{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39be45cb-508d-4aa1-b6ac-c7d799298609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch as th\n",
    "\n",
    "sys.path.insert(1, os.getcwd())\n",
    "\n",
    "from diffusion_openai import dist_util, logger\n",
    "from diffusion_openai.script_util import create_model_and_diffusion\n",
    "from diffusion_openai.video_datasets import load_data\n",
    "\n",
    "th.backends.cudnn.enabled = True\n",
    "th.backends.cudnn.benchmark = True\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MODEL_PATH = \"conditional_ramvid.pt\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8d6077f71c010e8"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416fe895-4d99-4091-a67f-f409d716c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Parameters:\n",
    "    clip_denoised=True\n",
    "    num_samples=100\n",
    "    batch_size=1\n",
    "    use_ddim=False\n",
    "    model_path=\"\"\n",
    "    seq_len=20\n",
    "    sampling_type=\"generation\"\n",
    "    cond_frames=\"0,1,2,3,\"\n",
    "    cond_generation=True\n",
    "    resample_steps=1\n",
    "    data_dir=''\n",
    "    save_gt=False\n",
    "    seed=42\n",
    "    data_dir=\"../../data_samples/gif_64\"\n",
    "    image_size=64\n",
    "    class_cond=False\n",
    "    deterministic=False\n",
    "    rgb=True\n",
    "    seq_len=20\n",
    "    n_samples = 1\n",
    "    output_dir = \"generated_for_evaluation\"\n",
    "\n",
    "args = Parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be4405d1-1954-4442-b5fb-6e8f82190902",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = dict(\n",
    "    image_size=64,\n",
    "    class_cond=False,\n",
    "    learn_sigma=False,\n",
    "    sigma_small=False,\n",
    "    num_channels=128,\n",
    "    num_res_blocks=3,\n",
    "    scale_time_dim=0,\n",
    "    num_heads=4,\n",
    "    num_heads_upsample=1,\n",
    "    attention_resolutions=\"16,8\",\n",
    "    dropout=0.0,\n",
    "    diffusion_steps=1000,\n",
    "    noise_schedule=\"linear\",\n",
    "    timestep_respacing=\"\",\n",
    "    use_kl=False,\n",
    "    predict_xstart=False,\n",
    "    rescale_timesteps=True,\n",
    "    rescale_learned_sigmas=True,\n",
    "    use_checkpoint=False,\n",
    "    use_scale_shift_norm=True,\n",
    "    rgb=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0c39d9b-13a3-4c8e-8fd4-4a5ecc470c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Logging to /home/s_gladkykh/thesis/sky-diffusion/ramvid_notebooks/logs_sampling\n"
     ]
    }
   ],
   "source": [
    "dist_util.setup_dist()\n",
    "logger.configure(dir=\"logs_sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d1194e-412d-4f6b-8ed2-d2f850368035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cond_frames: [0, 1, 2, 3]\n",
      "ref_frames: [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "seq_len: 20\n"
     ]
    }
   ],
   "source": [
    "cond_kwargs = {}\n",
    "cond_frames = []\n",
    "if args.cond_generation:\n",
    "    data = load_data(\n",
    "        data_dir=args.data_dir,\n",
    "        batch_size=1,\n",
    "        image_size=64,\n",
    "        class_cond=False,\n",
    "        deterministic=False,\n",
    "        rgb=True,\n",
    "        seq_len=20\n",
    "    )\n",
    "    \n",
    "    num = \"\"\n",
    "    for i in args.cond_frames:\n",
    "        if i == \",\":\n",
    "            cond_frames.append(int(num))\n",
    "            num = \"\"\n",
    "        else:\n",
    "            num = num + i\n",
    "    print(num)\n",
    "    ref_frames = list(i for i in range(args.seq_len) if i not in cond_frames)\n",
    "    logger.log(f\"cond_frames: {cond_frames}\")\n",
    "    logger.log(f\"ref_frames: {ref_frames}\")\n",
    "    logger.log(f\"seq_len: {args.seq_len}\")\n",
    "    cond_kwargs[\"resampling_steps\"] = args.resample_steps\n",
    "cond_kwargs[\"cond_frames\"] = cond_frames\n",
    "cond_kwargs[\"saver\"] = None\n",
    "\n",
    "if args.rgb:\n",
    "    channels = 3\n",
    "else:\n",
    "    channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a09d4105-005a-452e-8d59-f55a0ccc8bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407ee2fe-0216-4a86-afbc-86acdfdb33f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling...\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "def create_gif(arr, gif_path, duration=100, size=64):\n",
    "    image_list = [Image.fromarray(np.uint8(myarray*255)) for myarray in arr]\n",
    "\n",
    "    image_list[0].save(\n",
    "            gif_path,\n",
    "            save_all=True,\n",
    "            append_images=image_list[1:], # append rest of the images\n",
    "            duration=100, # in milliseconds\n",
    "            loop=1)\n",
    "    \n",
    "\n",
    "model, diffusion = create_model_and_diffusion(\n",
    "    **model_parameters\n",
    ")\n",
    "\n",
    "model.load_state_dict(\n",
    "    dist_util.load_state_dict(MODEL_PATH, map_location=\"cpu\")\n",
    ")\n",
    "model.to(dist_util.dev())\n",
    "model.eval()\n",
    "\n",
    "\n",
    "logger.log(\"sampling...\")\n",
    "all_videos = []\n",
    "all_gt = []\n",
    "generated_num = 0\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "while generated_num < args.n_samples:\n",
    "    if args.cond_generation:\n",
    "        video, _ = next(data)\n",
    "        # for j in range(0, video.shape[0]):\n",
    "        #     create_gif(((video[j] + 1) / 2).permute(1,2,3,0).cpu().numpy(), f\"original_for_evaluation/{iteration*video.shape[0]+j}.gif\")\n",
    "        cond_kwargs[\"cond_img\"] = video[:,:,cond_frames].to(dist_util.dev()) \n",
    "        video = video.to(dist_util.dev())\n",
    "\n",
    "\n",
    "    sample_fn = (\n",
    "        diffusion.p_sample_loop if not args.use_ddim else diffusion.ddim_sample_loop\n",
    "    )\n",
    "\n",
    "    sample = sample_fn(\n",
    "        model,\n",
    "        (args.batch_size, channels, args.seq_len, args.image_size, args.image_size),\n",
    "        clip_denoised=args.clip_denoised,\n",
    "        progress=False,\n",
    "        cond_kwargs=cond_kwargs\n",
    "    )\n",
    "\n",
    "    all_videos.append(sample)\n",
    "    generated_num += args.batch_size\n",
    "    sample = ((sample + 1) / 2).permute(0, 2, 3, 4, 1).cpu().numpy()\n",
    "    for i in range(sample.shape[0]):\n",
    "        create_gif(sample[i], f\"{args.output_dir}/{i+generated_num*sample.shape[0]}.gif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce3e6c3-cd21-4fca-8b4e-b08d3eaf6267",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee3b294-8b36-43a5-8c0a-aaed7c89ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_videos[0].view(-1,20,3,64,64).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b659e-90eb-46a4-92c1-4413b0e70b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in range(20):\n",
    "    imag = sample[0][frame]\n",
    "\n",
    "    plt.imshow(imag)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1061053-96b3-48f6-bc4b-a19a2ff7dcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "593ae0ba-fa11-4706-9d75-a249f35d742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from diffusers import UNet2DModel, DDIMScheduler, DDIMPipeline\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "from diffusers.utils import make_image_grid\n",
    "from huggingface_hub import create_repo, upload_folder\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dafc903d-a3dc-4f7a-befe-c0bf8d08ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SkyDatasetUnconditional(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_data_folder=\"/projects/SkyGAN/clouds_fisheye\",\n",
    "        desc_file=\"processed_1K_JPGs.txt\",\n",
    "        transform=None,\n",
    "    ):\n",
    "        self._root_data_folder = root_data_folder\n",
    "        self._desc_file = desc_file\n",
    "\n",
    "        self._image_path_list = self._get_image_paths()\n",
    "        self._n_samples = len(self._image_path_list)\n",
    "\n",
    "        self._transform = transform\n",
    "\n",
    "    def _get_image_paths(self):\n",
    "        file_path = os.path.join(\n",
    "            self._root_data_folder,\n",
    "            self._desc_file,\n",
    "        )\n",
    "        try:\n",
    "            with open(file_path) as f:\n",
    "                paths = f.read().strip().split(\"\\n\")\n",
    "                paths = list(\n",
    "                    map(\n",
    "                        lambda x: os.path.join(\n",
    "                            self._root_data_folder,\n",
    "                            x,\n",
    "                        ),\n",
    "                        paths,\n",
    "                    )\n",
    "                )\n",
    "            return paths\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"Could not find file {self._desc_file} enumerating all image paths\")\n",
    "        except IOError:\n",
    "            raise IOError(f\"An IOError occured while reading file {file_path}. Check correctness of the contents\")\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        try:\n",
    "            sample = Image.open(self._image_path_list[item])\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(\n",
    "                f\"Could not open file {self._image_path_list[item]}. . Check correctness of the description file {self._desc_file}\"\n",
    "            )\n",
    "\n",
    "        if self._transform:\n",
    "            sample = self._transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._image_path_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf30074-0fc3-468a-a747-a0d51a81cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    image_size = 512  # the generated image resolution\n",
    "    train_batch_size = 4\n",
    "    eval_batch_size = 16  # how many images to sample during evaluation\n",
    "    num_epochs = 50\n",
    "    gradient_accumulation_steps = 1\n",
    "    learning_rate = 1e-5\n",
    "    lr_warmup_steps = 500\n",
    "    save_image_epochs = 3\n",
    "    save_model_epochs = 3\n",
    "    mixed_precision = \"fp16\"  # `no` for float32, `fp16` for automatic mixed precision\n",
    "    output_dir = \"sky_diffusion_ddim_512_lr1e-5_bs4_e50\"  # the model name locally and on the HF Hub\n",
    "\n",
    "    push_to_hub = True  # whether to upload the saved model to the HF Hub\n",
    "    hub_model_id = \"sky_diffusion_ddim_512_lr1e-5_bs4_e50\"  # the name of the repository to create on the HF Hub\n",
    "    hub_private_repo = False\n",
    "    overwrite_output_dir = True  # overwrite the old model when re-running the notebook\n",
    "    seed = 42\n",
    "\n",
    "\n",
    "config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5efc649-7f60-4cdb-b4e0-8d41a4ccfc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(config: argparse.Namespace) -> UNet2DModel:\n",
    "    return UNet2DModel(\n",
    "        sample_size=config.image_size,\n",
    "        in_channels=3,\n",
    "        out_channels=3,\n",
    "        layers_per_block=2,\n",
    "        block_out_channels=(128, 128, 256, 256, 512, 512),\n",
    "        down_block_types=(\n",
    "            \"DownBlock2D\",\n",
    "            \"DownBlock2D\",\n",
    "            \"DownBlock2D\",\n",
    "            \"DownBlock2D\",\n",
    "            \"AttnDownBlock2D\",\n",
    "            \"DownBlock2D\",\n",
    "        ),\n",
    "        up_block_types=(\n",
    "            \"UpBlock2D\",\n",
    "            \"AttnUpBlock2D\",\n",
    "            \"UpBlock2D\",\n",
    "            \"UpBlock2D\",\n",
    "            \"UpBlock2D\",\n",
    "            \"UpBlock2D\",\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce2a655-3e42-4f0c-bc3b-836318f906d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(config, epoch, pipeline):\n",
    "    images = pipeline(\n",
    "        batch_size=config.eval_batch_size,\n",
    "        generator=torch.manual_seed(config.seed),\n",
    "    ).images\n",
    "\n",
    "    image_grid = make_image_grid(images, rows=4, cols=4)\n",
    "\n",
    "    test_dir = os.path.join(config.output_dir, \"samples\")\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    image_grid.save(f\"{test_dir}/{(epoch + 1):04d}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad99ce23-9b37-46a6-914b-50a6ed769316",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(config.output_dir):\n",
    "    os.makedirs(config.output_dir)\n",
    "    print(f\"Folder {config.output_dir} created\")\n",
    "\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((config.image_size, config.image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5]),\n",
    "    ]\n",
    ")\n",
    "dataset = SkyDatasetUnconditional(transform=preprocess)\n",
    "train_dataloader = DataLoader(dataset=dataset, batch_size=config.train_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56e61301-776a-47eb-88e4-5b61c7b313ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(config)\n",
    "noise_scheduler = DDIMScheduler()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=config.lr_warmup_steps,\n",
    "    num_training_steps=(len(train_dataloader) * config.num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ce5ccad-f254-486f-8868-000e4ff4316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(config, model, noise_scheduler, optimizer, train_dataloader, lr_scheduler):\n",
    "    accelerator = Accelerator(\n",
    "        mixed_precision=config.mixed_precision,\n",
    "        gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "        log_with=\"tensorboard\",\n",
    "        project_dir=os.path.join(config.output_dir, \"logs\"),\n",
    "    )\n",
    "    if accelerator.is_main_process:\n",
    "        if config.output_dir is not None:\n",
    "            os.makedirs(config.output_dir, exist_ok=True)\n",
    "        if config.push_to_hub:\n",
    "            print()\n",
    "            repo_id = create_repo(repo_id=config.hub_model_id or Path(config.output_dir).name, exist_ok=True).repo_id\n",
    "        accelerator.init_trackers(\"train_example\")\n",
    "\n",
    "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
    "        model, optimizer, train_dataloader, lr_scheduler\n",
    "    )\n",
    "\n",
    "    global_step = 0\n",
    "\n",
    "    for epoch in range(config.num_epochs):\n",
    "        progress_bar = tqdm(total=len(train_dataloader), disable=not accelerator.is_local_main_process)\n",
    "        progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            clean_images = batch\n",
    "            noise = torch.randn(clean_images.shape, device=clean_images.device)\n",
    "            bs = clean_images.shape[0]\n",
    "\n",
    "            timesteps = torch.randint(\n",
    "                0, noise_scheduler.config.num_train_timesteps, (bs,), device=clean_images.device, dtype=torch.int64\n",
    "            )\n",
    "\n",
    "            noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)\n",
    "\n",
    "            with accelerator.accumulate(model):\n",
    "                noise_pred = model(noisy_images, timesteps, return_dict=False)[0]\n",
    "                loss = F.mse_loss(noise_pred, noise)\n",
    "                accelerator.backward(loss)\n",
    "\n",
    "                accelerator.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            progress_bar.update(1)\n",
    "            logs = {\"loss\": loss.detach().item(), \"lr\": lr_scheduler.get_last_lr()[0], \"step\": global_step}\n",
    "            progress_bar.set_postfix(**logs)\n",
    "            accelerator.log(logs, step=global_step)\n",
    "            global_step += 1\n",
    "\n",
    "        if accelerator.is_main_process:\n",
    "            pipeline = DDIMPipeline(unet=accelerator.unwrap_model(model), scheduler=noise_scheduler)\n",
    "\n",
    "            if (epoch + 1) % config.save_image_epochs == 0 or epoch == config.num_epochs - 1:\n",
    "                evaluate(config, epoch + 1, pipeline)\n",
    "\n",
    "            if (epoch + 1) % config.save_model_epochs == 0 or epoch == config.num_epochs - 1:\n",
    "                torch.save(model.state_dict(), f\"{config.output_dir}/models/model{epoch + 1}.pt\")\n",
    "                if config.push_to_hub:\n",
    "                    upload_folder(\n",
    "                        repo_id=repo_id,\n",
    "                        folder_path=config.output_dir,\n",
    "                        commit_message=f\"Epoch {epoch + 1}\",\n",
    "                        ignore_patterns=[\"step_*\", \"epoch_*\"],\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c716e8fd-28e7-42b4-a80e-1d6cc0ea24c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on one GPU.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a332fafda04dbf999b05f6a76f2846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4710 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = (config, model, noise_scheduler, optimizer, train_dataloader, lr_scheduler)\n",
    "notebook_launcher(train_loop, args, num_processes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9745955e-0bd8-4a33-84df-c6037ebf8b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1d5500-7258-4bad-b9b9-741a625f6a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
